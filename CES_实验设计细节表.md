# CES方法修改后的实验设计细节表

## 一、核心机制验证实验

### 1.1 纠错半径-专家替换数匹配实验

| 实验名称 | 纠错半径-专家替换数匹配验证 |
|---------|---------------------------|
| **实验目标** | 验证ECC纠错半径与专家替换数的匹配性，证明ECC的有效性 |
| **控制变量** | ECC类型固定为LDPC，签名长度L_code=64，paraphrase生成协议一致 |
| **自变量** | 纠错半径 t ∈ {1,2,3,4} |
| **因变量** | 水印检测准确率 |
| **实验设置** | 在PAWS数据集上生成不同替换数的专家选择序列 |
| **观测指标** | 绘制"专家替换数-t"与"水印检测准确率"的关系曲线 |
| **预期结果** | 当替换数≤t时，检测准确率≥95%；超出t时准确率显著下降 |
| **统计方法** | 1000次独立试验，计算95%置信区间 |
| **实验数据** | 每个t值测试1000个paraphrase对，记录准确率分布 |

### 1.2 软/硬判决解码对比实验

| 实验名称 | 软判决vs硬判决解码性能对比 |
|---------|-------------------------|
| **实验目标** | 验证软判决相对硬判决的性能提升幅度 |
| **控制变量** | 相同ECC参数，相同专家替换数，相同测试数据 |
| **自变量** | 解码方式（硬判决 vs 软判决） |
| **因变量** | 纠错成功率、误检率、计算开销 |
| **实验设置** | 在相同专家替换数下分别采用两种解码方式 |
| **观测指标** | 纠错成功率提升≥15%，误检率降低≥5% |
| **预期结果** | 软判决在保持计算效率的同时显著提升性能 |
| **统计方法** | 配对t检验，p < 0.01，1000次独立试验 |
| **性能指标** | 计算LLR和软解码的额外延迟vs硬判决基线 |

## 二、场景化专家替换信道分析实验

### 2.1 Paraphrase类型分类实验

| 实验名称 | 场景化专家替换信道分析 |
|---------|---------------------|
| **实验目标** | 量化不同类型paraphrase对专家选择的差异化影响 |
| **数据来源** | PAWS数据集、QQP数据集 |
| **分类标准** | 低扰动、中扰动、高扰动三类paraphrase |
| **统计指标** | 专家替换数t的分布区间 |
| **预期分布** | 低扰动t∈[0,2]，中扰动t∈[2,5]，高扰动t∈[5,8] |
| **数据量** | 每类1000个paraphrase对 |
| **分析方法** | 统计t值的分布，计算P(t≤k)的概率边界 |

### 2.2 LLR计算有效性验证

| 实验名称 | LLR计算逻辑验证 |
|---------|----------------|
| **实验目标** | 验证LLR计算公式的准确性和理论证明 |
| **测试场景** | 不同MoE模型、不同Top-k值 |
| **验证方法** | 理论证明+实验验证 |
| **关键公式** | LLR_i = log[(R_i - θ)/(max(R - θ) + ε)] |
| **理论证明** | 基于MoE路由机制的Lipschitz连续性 |
| **实验验证** | 验证LLR变化与专家替换概率的正相关关系 |
| **统计方法** | 皮尔逊相关系数分析 |

## 三、工程落地验证实验

### 3.1 ECC参数选择指南验证

| 实验名称 | 场景自适应ECC参数选择 |
|---------|---------------------|
| **实验目标** | 验证参数选择指南的实用性 |
| **测试场景** | 低扰动、中扰动、高扰动三种场景 |
| **参数组合** | 不同ECC类型、纠错半径、签名长度 |
| **评估指标** | 检测准确率、计算效率、存储开销 |
| **推荐配置** | 基于场景的ECC参数推荐表 |
| **验证方法** | 在真实paraphrase数据上测试推荐参数 |
| **成功标准** | 推荐参数在对应场景下达到≥95%准确率 |

### 3.2 MoE模型兼容性测试

| 实验名称 | 多模型兼容性验证 |
|---------|-----------------|
| **实验目标** | 验证方法对不同MoE模型的兼容性 |
| **测试模型** | Mixtral-8x7B、OpenMoE-12B、Switch-Transformer |
| **配置变化** | 专家数量(8,12,16)、Top-k值(2,4,8) |
| **评估指标** | 检测准确率方差≤3% |
| **兼容性标准** | Top-k≤8时准确率波动≤3% |
| **实现要求** | 无需模型架构修改，仅需访问路由权重 |
| **性能基准** | 与基线方法在相同配置下的性能对比 |

## 四、综合性能评估实验

### 4.1 端到端性能对比

| 实验名称 | 综合性能评估 |
|---------|-------------|
| **对比方法** | CES、TGH、KLQ vs 基线方法 |
| **评估维度** | 鲁棒性、不可感知性、效率、容量 |
| **测试数据** | PAWS、QQP、C4语料库 |
| **性能指标** | AUC、ΔPPL、ms/token、bits/token |
| **预期结果** | MoE原生方法在所有维度上优于基线 |
| **统计方法** | 多因素方差分析(ANOVA) |
| **显著性水平** | p < 0.01，多重比较校正 |

### 4.2 攻击鲁棒性测试

| 实验名称 | 综合攻击鲁棒性评估 |
|---------|-------------------|
| **攻击类型** | 语义paraphrase、模型变换、白盒攻击 |
| **攻击方法** | PAWS攻击、模型微调、Router-PGD |
| **评估指标** | ROC-AUC、TPR@FPR、攻击成功率 |
| **鲁棒性标准** | 在最强攻击下保持≥90%检测准确率 |
| **对比基线** | 传统水印方法、路由权重LSH方法 |
| **统计方法** | 攻击成功率vs扰动半径的关系分析 |

## 五、实验实施计划

### 5.1 实验时间安排
- **第1-2周**: 场景化专家替换信道分析实验
- **第3-4周**: CES核心机制验证实验  
- **第5-6周**: 工程落地验证实验
- **第7-8周**: 综合性能评估实验

### 5.2 资源需求
- **计算资源**: 4×A100 GPU，用于大规模MoE模型推理
- **数据资源**: PAWS、QQP、C4数据集
- **软件环境**: PyTorch、Transformers、自定义ECC库

### 5.3 成功标准
- **理论验证**: 所有理论证明通过数学验证
- **实验验证**: 关键指标达到预期目标
- **工程验证**: 参数指南在实际应用中有效
- **统计验证**: 所有结果通过统计显著性检验

## 六、预期贡献

### 6.1 理论贡献
- 场景化专家替换信道建模
- 完整的LLR计算理论框架
- 确定性鲁棒性边界证明

### 6.2 实验贡献  
- CES核心机制的直接验证
- 软/硬判决解码的量化对比
- 场景自适应参数选择指南

### 6.3 工程贡献
- 实用的参数选择指南
- 多模型兼容性验证
- 端到端性能基准测试

